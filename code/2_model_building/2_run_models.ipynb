{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "939504c9",
   "metadata": {},
   "source": [
    "# 3. Run ML Models\n",
    "This notebook executes both Logistic Regression and XGBoost models on the full set of features as well as a reduced set of top two features, aiming to compare the performance across these scenarios. The results are then visualized, specifically focusing on the ROC curves, and relevant performance metrics are stored for future reference and analysis.\n",
    "\n",
    "### Objective:\n",
    "To execute various machine learning models using the dataset provided and assess their performance on predicting the given outcome.\n",
    "\n",
    "### Data Overview:\n",
    "\n",
    "* Source: The data for this notebook is sourced from various CSV files located within directories defined in the notebook.\n",
    "* Features: The dataset contains a mix of numerical and categorical features. Some key features include 'start_glc', 'duration', and many others.\n",
    "* Target Variable: The prediction target is 'y_3', which is possibly a binary outcome indicating a certain event or condition.\n",
    "\n",
    "### Sections:\n",
    "\n",
    "1. Setup: Importing necessary libraries and defining paths.\n",
    "2. Data Loading: Reading the required datasets from their respective directories.\n",
    "3. Data Preparation: Setting up dataframes to store results and setting up predictor variables and target variable.\n",
    "4. Model Execution:\n",
    "        All Features:\n",
    "            Logistic Regression: Execution of logistic regression using all features, hyperparameter tuning, and storing of results.\n",
    "            XGBoost: Execution of XGBoost using all features and storing of results.\n",
    "        Top Two Features:\n",
    "            Logistic Regression: Execution of logistic regression using only the top two features, 'start_glc' and 'duration', and storing of results.\n",
    "            XGBoost: Execution of XGBoost using only the top two features and storing of results.\n",
    "5. Results Compilation: Storing of model results, calculation of mean results, and appending of results to dataframes.\n",
    "6. Data Saving: Storing results in specified directories."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f34d55c8",
   "metadata": {},
   "source": [
    "## 3.0. Packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f38c273-ed18-4be0-8bfe-1bfae59294c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import ml_helper as ml_help\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import sys\n",
    "path = \"../../diametrics\"\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d2ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "directory = '../../data/tidy_data/final_df/'\n",
    "probability_results_directory = '../../results/probability_results/'\n",
    "k_fold_results_directory = '../../results/k_fold_results/'\n",
    "threshold_results_directory = '../../results/threshold_results/'\n",
    "mean_results_directory = '../../results/mean_results/'\n",
    "dict_directory = '../../results/dict_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84b2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(directory + 'df.csv')\n",
    "strat = df['stratify']\n",
    "X = pd.read_csv(directory + 'X.csv')\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb450bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dfs for results\n",
    "df_with_probas = df.copy()\n",
    "mean_results = pd.DataFrame()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e120f61a",
   "metadata": {},
   "source": [
    "## 3.1. All features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d157acc",
   "metadata": {},
   "source": [
    "### 3.1.1. Logistic regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4789fe38",
   "metadata": {},
   "source": [
    "# Run the LR model, uses hyperopt for HP tuning, get accuracy, indices and probabilities for each fold\n",
    "lr_all_k_fold_results, lr_all_test_sets_index, lr_all_predicted_probas, lr_all_observed, lr_all_shap_values, lr_all_coeffs, lr_all_hps = ml_help.k_fold_accuracies(X, y, strat, True, 'all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0e8912b",
   "metadata": {},
   "source": [
    "# Store results in dictionary\n",
    "lr_all_results = {'X':X,\n",
    "              'probas':lr_all_predicted_probas, \n",
    "              'observed':lr_all_observed, \n",
    "              'shap':lr_all_shap_values, \n",
    "              'coeffs':lr_all_coeffs}\n",
    "\n",
    "with open(dict_directory+\"lr_results_all\", \"wb\") as fp:   \n",
    "    #Pickling \n",
    "    pickle.dump(lr_all_results, fp) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d20f2d6",
   "metadata": {},
   "source": [
    "# Add the mean accuracy to a table for easy perusal\n",
    "mean_results = ml_help.add_mean_to_df(mean_results, lr_all_k_fold_results, 'lr', 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314b8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a probability column to the whole dataset to ensure \n",
    "df_with_probas = ml_help.add_proba_col(df_with_probas, lr_all_test_sets_index, lr_all_predicted_probas, 'probas_lr_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a17011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "lr_all_k_fold_results.to_csv(k_fold_results_directory+'lr_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbc8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hyperparameters\n",
    "pd.DataFrame(lr_all_hps).to_csv('../../results/hyperparameters/lr_all.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd647777",
   "metadata": {},
   "source": [
    "### 3.1.2. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9647fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-30 11:42:08,095]\u001b[0m A new study created in memory with name: no-name-cc79c65e-7b65-4e5e-bb54-6257b36abff7\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:43:31,185]\u001b[0m Trial 0 finished with value: 0.8805406 and parameters: {'n_estimators': 360, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.88069840519828, 'colsample_bytree': 0.7745339339541701, 'eta': 0.12663788179159863, 'learning_rate': 0.2709552449490183, 'reg_alpha': 2, 'reg_lambda': 5, 'gamma': 1}. Best is trial 0 with value: 0.8805406.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:45:01,949]\u001b[0m Trial 1 finished with value: 0.8834674000000001 and parameters: {'n_estimators': 870, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8117659031059572, 'colsample_bytree': 0.9785914398424478, 'eta': 0.22353632863973977, 'learning_rate': 0.030517321256285642, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 0}. Best is trial 1 with value: 0.8834674000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:45:39,009]\u001b[0m Trial 2 finished with value: 0.8943000999999999 and parameters: {'n_estimators': 799, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.8157120301399448, 'colsample_bytree': 0.7272274676551804, 'eta': 0.18907309137661854, 'learning_rate': 0.06818466106256252, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 1}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:45:58,343]\u001b[0m Trial 3 finished with value: 0.8519398 and parameters: {'n_estimators': 306, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.7524750244835581, 'colsample_bytree': 0.25217388858517326, 'eta': 0.11573965123738104, 'learning_rate': 0.0068523694723794685, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 3}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:46:57,910]\u001b[0m Trial 4 finished with value: 0.8928106999999998 and parameters: {'n_estimators': 417, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.7787541323304281, 'colsample_bytree': 0.5767164275786834, 'eta': 0.22089823823837146, 'learning_rate': 0.0800692102277484, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 2}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:46:59,022]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:00,364]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:01,729]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:02,810]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:03,744]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:04,931]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:06,416]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:07,731]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:10,004]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:11,250]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:12,565]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:13,763]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:15,192]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:35,817]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:37,704]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:39,152]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:47,323]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:47:55,413]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:50:50,571]\u001b[0m Trial 23 finished with value: 0.889123 and parameters: {'n_estimators': 718, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.8474234867001, 'colsample_bytree': 0.8768345944142775, 'eta': 0.19490665718767652, 'learning_rate': 0.10519274833053242, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 0}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:50:58,463]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:51:01,848]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:51:08,446]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:54:19,212]\u001b[0m Trial 27 finished with value: 0.8854959000000001 and parameters: {'n_estimators': 625, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.8442350281731825, 'colsample_bytree': 0.7122374658777076, 'eta': 0.25865150240360735, 'learning_rate': 0.20355959105241728, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 2}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:55:01,662]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:56:32,399]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 41.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:56:33,722]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:57:02,727]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 60.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:57:37,631]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 60.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:07,929]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:33,755]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:35,077]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:38,821]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:41,209]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:42,455]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:58:43,688]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:59:11,133]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 60.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:59:22,921]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:59:31,763]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:59:33,912]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 11:59:37,077]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:00:42,341]\u001b[0m Trial 45 finished with value: 0.890992 and parameters: {'n_estimators': 796, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.6886856616256783, 'colsample_bytree': 0.9090747077198035, 'eta': 0.1714914640160149, 'learning_rate': 0.09155249071350904, 'reg_alpha': 0, 'reg_lambda': 2, 'gamma': 5}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:01:33,749]\u001b[0m Trial 46 finished with value: 0.8914298 and parameters: {'n_estimators': 615, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.6861085161695476, 'colsample_bytree': 0.908252400234641, 'eta': 0.14718447923083294, 'learning_rate': 0.08878887991787952, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 5}. Best is trial 2 with value: 0.8943000999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:01:34,860]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:01:36,690]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:01:37,840]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:02:36,072]\u001b[0m A new study created in memory with name: no-name-a13db6e3-eabe-40c3-94e3-361b95a9c66f\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:03:17,889]\u001b[0m Trial 0 finished with value: 0.8657056000000001 and parameters: {'n_estimators': 686, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.4692095561022829, 'colsample_bytree': 0.8077648647313924, 'eta': 0.24754347815594807, 'learning_rate': 0.012073033622968575, 'reg_alpha': 5, 'reg_lambda': 0, 'gamma': 0}. Best is trial 0 with value: 0.8657056000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:03:52,462]\u001b[0m Trial 1 finished with value: 0.8611906000000001 and parameters: {'n_estimators': 984, 'max_depth': 12, 'min_child_weight': 9, 'subsample': 0.8824162587351729, 'colsample_bytree': 0.2698627965436286, 'eta': 0.11453891367016057, 'learning_rate': 0.007074448415315007, 'reg_alpha': 2, 'reg_lambda': 0, 'gamma': 0}. Best is trial 0 with value: 0.8657056000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:04:39,349]\u001b[0m Trial 2 finished with value: 0.8598058 and parameters: {'n_estimators': 464, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.590522670801336, 'colsample_bytree': 0.7439584723350756, 'eta': 0.15696533070376678, 'learning_rate': 0.4675130571214561, 'reg_alpha': 4, 'reg_lambda': 2, 'gamma': 0}. Best is trial 0 with value: 0.8657056000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:05:27,525]\u001b[0m Trial 3 finished with value: 0.8686501 and parameters: {'n_estimators': 623, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.5695249236423059, 'colsample_bytree': 0.5570519795327975, 'eta': 0.195072611904341, 'learning_rate': 0.2213122120497582, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 5}. Best is trial 3 with value: 0.8686501.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:23,610]\u001b[0m Trial 4 finished with value: 0.8673013999999999 and parameters: {'n_estimators': 470, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.47055148993833545, 'colsample_bytree': 0.8206616522624819, 'eta': 0.2093271634074328, 'learning_rate': 0.2741500891723686, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 1}. Best is trial 3 with value: 0.8686501.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:24,590]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:25,614]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:26,547]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:27,482]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:28,439]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:29,532]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:35,085]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:36,308]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:40,458]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:41,626]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:44,828]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:06:50,271]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:08:00,318]\u001b[0m Trial 17 finished with value: 0.8792018 and parameters: {'n_estimators': 597, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9563995781226812, 'colsample_bytree': 0.6423409844894109, 'eta': 0.25431774550850067, 'learning_rate': 0.3267352316518607, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 4}. Best is trial 17 with value: 0.8792018.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:08:03,277]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:08:49,087]\u001b[0m Trial 19 finished with value: 0.8783343 and parameters: {'n_estimators': 797, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8354520560351424, 'colsample_bytree': 0.5131051960126354, 'eta': 0.2622826777985484, 'learning_rate': 0.38271448318067897, 'reg_alpha': 5, 'reg_lambda': 0, 'gamma': 5}. Best is trial 17 with value: 0.8792018.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:08:50,259]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:40,637]\u001b[0m Trial 21 finished with value: 0.8807517 and parameters: {'n_estimators': 698, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.8271751539556358, 'colsample_bytree': 0.54825644234361, 'eta': 0.2985799426499225, 'learning_rate': 0.2909029708678753, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 5}. Best is trial 21 with value: 0.8807517.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:41,843]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:43,579]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:44,684]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:45,912]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:47,746]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:49,353]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:50,533]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:09:52,172]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:10,605]\u001b[0m Trial 30 finished with value: 0.8813726000000001 and parameters: {'n_estimators': 380, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.9397341031439006, 'colsample_bytree': 0.6090752132536642, 'eta': 0.2247082292082399, 'learning_rate': 0.3228495687736949, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 3}. Best is trial 30 with value: 0.8813726000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:27,209]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:29,536]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:31,655]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:49,362]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:50,695]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:52,650]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:53,811]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:54,908]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:57,223]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:11:59,710]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:12:01,908]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:12:06,066]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:12:07,658]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:12:08,872]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:13:08,378]\u001b[0m Trial 45 finished with value: 0.8813497 and parameters: {'n_estimators': 716, 'max_depth': 11, 'min_child_weight': 8, 'subsample': 0.961034552209458, 'colsample_bytree': 0.6091456682411526, 'eta': 0.1969526630717901, 'learning_rate': 0.2878906583337322, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 4}. Best is trial 30 with value: 0.8813726000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:13:21,064]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:13:34,142]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:13:35,859]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:13:37,063]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:14:35,360]\u001b[0m A new study created in memory with name: no-name-ec98ea2b-bd23-4246-a47e-b112f3f025c9\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:14:56,099]\u001b[0m Trial 0 finished with value: 0.8583708 and parameters: {'n_estimators': 357, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.23923294203552345, 'colsample_bytree': 0.47149728047837275, 'eta': 0.12017962141152307, 'learning_rate': 0.012496591214089645, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 4}. Best is trial 0 with value: 0.8583708.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:16:15,162]\u001b[0m Trial 1 finished with value: 0.8876265999999999 and parameters: {'n_estimators': 892, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.9148471786535592, 'colsample_bytree': 0.6312667068346629, 'eta': 0.23970738744605669, 'learning_rate': 0.1124015234634345, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 0}. Best is trial 1 with value: 0.8876265999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:16:35,232]\u001b[0m Trial 2 finished with value: 0.8864127999999999 and parameters: {'n_estimators': 625, 'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.5309437449192638, 'colsample_bytree': 0.7148916996883612, 'eta': 0.20943348258725714, 'learning_rate': 0.28946925335641976, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 2}. Best is trial 1 with value: 0.8876265999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:15,433]\u001b[0m Trial 3 finished with value: 0.8913682999999999 and parameters: {'n_estimators': 428, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.6428815930370493, 'colsample_bytree': 0.7818642649451231, 'eta': 0.15475910578668534, 'learning_rate': 0.07454465135834931, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 5}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:33,625]\u001b[0m Trial 4 finished with value: 0.8415215999999999 and parameters: {'n_estimators': 317, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.2463065947648768, 'colsample_bytree': 0.39718882924191634, 'eta': 0.10124611108322128, 'learning_rate': 0.005143889781772217, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 2}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:41,793]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:42,766]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:53,079]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 58.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:54,384]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:55,375]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:17:56,813]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:18:32,077]\u001b[0m Trial 11 finished with value: 0.890388 and parameters: {'n_estimators': 979, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9977760777113487, 'colsample_bytree': 0.5467179767707121, 'eta': 0.21823647142739053, 'learning_rate': 0.13606766641488946, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 0}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:19:06,670]\u001b[0m Trial 12 finished with value: 0.8894399999999999 and parameters: {'n_estimators': 985, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9945999581157097, 'colsample_bytree': 0.5394838497650906, 'eta': 0.15504837906534022, 'learning_rate': 0.154433367063125, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 1}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:19:26,508]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 49.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:19:27,580]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:19:28,844]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:19:35,497]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:20:25,039]\u001b[0m Trial 17 finished with value: 0.8911861 and parameters: {'n_estimators': 987, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9949078478887856, 'colsample_bytree': 0.6457610021812719, 'eta': 0.2365240345375821, 'learning_rate': 0.16721512591116666, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 5}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:20:40,261]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:20:41,490]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:20:43,011]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:28,177]\u001b[0m Trial 21 finished with value: 0.8882205000000001 and parameters: {'n_estimators': 993, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.9532763809637153, 'colsample_bytree': 0.5825893437419434, 'eta': 0.2222983396877765, 'learning_rate': 0.1372992075790532, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 3}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:29,439]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:37,254]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:39,509]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:41,017]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:42,162]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:43,873]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:45,247]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:46,302]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:47,436]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:54,724]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:21:59,053]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:00,214]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:07,973]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:09,044]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:10,626]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:12,016]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:13,204]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:14,363]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:15,462]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:23,224]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:27,017]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:28,464]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:29,424]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:22:36,020]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:23:14,226]\u001b[0m Trial 46 finished with value: 0.8857668000000001 and parameters: {'n_estimators': 891, 'max_depth': 4, 'min_child_weight': 8, 'subsample': 0.8482479418449235, 'colsample_bytree': 0.8190949508989235, 'eta': 0.2811606692012501, 'learning_rate': 0.24442497600428956, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 0}. Best is trial 3 with value: 0.8913682999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:23:15,291]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:23:16,353]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:23:26,094]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 14.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:23:58,699]\u001b[0m A new study created in memory with name: no-name-7142d5b6-2a64-4350-803d-8d6fc03f5c1e\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:24:20,136]\u001b[0m Trial 0 finished with value: 0.8499307 and parameters: {'n_estimators': 690, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.2139563575108353, 'colsample_bytree': 0.6744424226386687, 'eta': 0.12154109257059055, 'learning_rate': 0.2292876633431067, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 3}. Best is trial 0 with value: 0.8499307.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:24:55,387]\u001b[0m Trial 1 finished with value: 0.8601639999999999 and parameters: {'n_estimators': 101, 'max_depth': 5, 'min_child_weight': 3, 'subsample': 0.8222229835929515, 'colsample_bytree': 0.42521462387082487, 'eta': 0.28305287789937156, 'learning_rate': 0.009776321797331679, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 1}. Best is trial 1 with value: 0.8601639999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:25:52,492]\u001b[0m Trial 2 finished with value: 0.8706517000000001 and parameters: {'n_estimators': 739, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6395678145693604, 'colsample_bytree': 0.7453294063410023, 'eta': 0.1273440771256923, 'learning_rate': 0.010518661731563073, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 4}. Best is trial 2 with value: 0.8706517000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:26:13,438]\u001b[0m Trial 3 finished with value: 0.8698697000000001 and parameters: {'n_estimators': 317, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.5763603217882742, 'colsample_bytree': 0.25941348319504587, 'eta': 0.23536513916656499, 'learning_rate': 0.2039932797179029, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 3}. Best is trial 2 with value: 0.8706517000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:26:43,449]\u001b[0m Trial 4 finished with value: 0.8637263 and parameters: {'n_estimators': 174, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.8983137886536194, 'colsample_bytree': 0.5275465642701447, 'eta': 0.1256305535437608, 'learning_rate': 0.005632517030641699, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 2}. Best is trial 2 with value: 0.8706517000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:26:44,482]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:26:45,643]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:26:46,688]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:27:37,358]\u001b[0m Trial 8 finished with value: 0.8821113 and parameters: {'n_estimators': 126, 'max_depth': 9, 'min_child_weight': 9, 'subsample': 0.5327156518300613, 'colsample_bytree': 0.6172633350343861, 'eta': 0.21710103275759168, 'learning_rate': 0.030742727356039168, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:27:38,593]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:27:41,920]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:28:46,585]\u001b[0m Trial 11 finished with value: 0.8813652999999999 and parameters: {'n_estimators': 653, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.67688180595995, 'colsample_bytree': 0.7920598764470396, 'eta': 0.1962807181831675, 'learning_rate': 0.02689856165703823, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:28:47,916]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:29:05,929]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:30:03,827]\u001b[0m Trial 14 finished with value: 0.8790955 and parameters: {'n_estimators': 888, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.7216945794857469, 'colsample_bytree': 0.6693627192609365, 'eta': 0.24476478325737064, 'learning_rate': 0.0190712187284589, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:30:05,199]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:30:06,967]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:31:19,773]\u001b[0m Trial 17 finished with value: 0.8761437000000001 and parameters: {'n_estimators': 764, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.755439203738637, 'colsample_bytree': 0.672116840099159, 'eta': 0.20824708529542785, 'learning_rate': 0.023500655988348686, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 0}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:31:21,179]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:31:22,517]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:31:23,819]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:32:38,331]\u001b[0m Trial 21 finished with value: 0.8779009 and parameters: {'n_estimators': 946, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.7231303070304026, 'colsample_bytree': 0.644235964064282, 'eta': 0.25756265400788414, 'learning_rate': 0.019091130622574504, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:33:37,020]\u001b[0m Trial 22 finished with value: 0.8762893999999999 and parameters: {'n_estimators': 840, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.6857642132773871, 'colsample_bytree': 0.5980929046377987, 'eta': 0.24259956331778104, 'learning_rate': 0.01631650850870205, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 2}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:33:38,675]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:33:40,631]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:33:41,959]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:34:44,524]\u001b[0m Trial 26 finished with value: 0.8774991 and parameters: {'n_estimators': 852, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.6695778321355301, 'colsample_bytree': 0.8855988576326981, 'eta': 0.22742269674365503, 'learning_rate': 0.01330074540349111, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:34:45,577]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:34:47,251]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:34:48,471]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:34:50,044]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:43,991]\u001b[0m Trial 31 finished with value: 0.8782026 and parameters: {'n_estimators': 948, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.7321305538962587, 'colsample_bytree': 0.6458527511360775, 'eta': 0.25620855352744765, 'learning_rate': 0.01789190850085777, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:46,780]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:48,595]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:49,989]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:52,318]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:55,808]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:57,263]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:35:58,994]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:36:00,595]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:36:01,797]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:07,682]\u001b[0m Trial 41 finished with value: 0.8791047000000001 and parameters: {'n_estimators': 944, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.7189462990996959, 'colsample_bytree': 0.6200952180911763, 'eta': 0.2668542691871625, 'learning_rate': 0.019285081081395965, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 1}. Best is trial 8 with value: 0.8821113.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:09,147]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:10,495]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:11,670]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:14,031]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:15,343]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:16,720]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:17,900]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:19,482]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:34,499]\u001b[0m A new study created in memory with name: no-name-63f2e89b-5e2a-4ac8-8bc2-8ccbf91af034\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:37:58,580]\u001b[0m Trial 0 finished with value: 0.8919352999999999 and parameters: {'n_estimators': 970, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.46863020390342336, 'colsample_bytree': 0.46544609207031584, 'eta': 0.1332659880429467, 'learning_rate': 0.19090461933525069, 'reg_alpha': 5, 'reg_lambda': 5, 'gamma': 5}. Best is trial 0 with value: 0.8919352999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:39:22,827]\u001b[0m Trial 1 finished with value: 0.8902328 and parameters: {'n_estimators': 910, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.6564693460065891, 'colsample_bytree': 0.9806079362456672, 'eta': 0.13614911830802495, 'learning_rate': 0.18187004095909054, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 5}. Best is trial 0 with value: 0.8919352999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:40:52,288]\u001b[0m Trial 2 finished with value: 0.8922755 and parameters: {'n_estimators': 364, 'max_depth': 11, 'min_child_weight': 4, 'subsample': 0.7359865971314286, 'colsample_bytree': 0.8389205569147373, 'eta': 0.2494440852550826, 'learning_rate': 0.15023999249384298, 'reg_alpha': 4, 'reg_lambda': 5, 'gamma': 4}. Best is trial 2 with value: 0.8922755.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:42:14,232]\u001b[0m Trial 3 finished with value: 0.8882378 and parameters: {'n_estimators': 447, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7342298829594867, 'colsample_bytree': 0.8662064117011155, 'eta': 0.2510513631734711, 'learning_rate': 0.1293420023637872, 'reg_alpha': 2, 'reg_lambda': 5, 'gamma': 0}. Best is trial 2 with value: 0.8922755.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:43:02,137]\u001b[0m Trial 4 finished with value: 0.8902559999999999 and parameters: {'n_estimators': 265, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.5283983480393896, 'colsample_bytree': 0.6761788032172789, 'eta': 0.08371938707378991, 'learning_rate': 0.10254414981438965, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 3}. Best is trial 2 with value: 0.8922755.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:43:09,429]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:43:16,187]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:43:58,206]\u001b[0m Trial 7 finished with value: 0.8950004 and parameters: {'n_estimators': 396, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.9387613519555797, 'colsample_bytree': 0.7323951440984131, 'eta': 0.221287196805664, 'learning_rate': 0.1842208651103299, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 2}. Best is trial 7 with value: 0.8950004.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:09,557]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 21.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:20,991]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 17.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:22,186]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:23,681]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:25,947]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:28,182]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:29,215]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:33,618]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:35,909]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:38,788]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:39,903]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:41,338]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:42,440]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:43,616]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:44,598]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:45,700]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:46,893]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:47,932]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:50,024]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:51,363]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:44:52,479]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:45:10,712]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:45:13,568]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:45:18,465]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:45:20,866]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:10,512]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 67.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:11,689]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:35,327]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:36,490]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:37,983]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:39,253]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:46,722]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:47,950]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:53,285]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:46:55,936]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:47:03,361]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:47:26,342]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:47:29,920]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:47:48,577]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 32.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:48:37,760]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 44.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:48:39,036]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:48:40,550]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:49:15,965]\u001b[0m A new study created in memory with name: no-name-4041d457-120c-472e-a036-dbed4fde2acf\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:50:09,396]\u001b[0m Trial 0 finished with value: 0.8717765 and parameters: {'n_estimators': 186, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.9736890933009716, 'colsample_bytree': 0.5465433429343318, 'eta': 0.15277867742412377, 'learning_rate': 0.018385544441985393, 'reg_alpha': 4, 'reg_lambda': 4, 'gamma': 2}. Best is trial 0 with value: 0.8717765.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:51:11,641]\u001b[0m Trial 1 finished with value: 0.8825137000000002 and parameters: {'n_estimators': 352, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.2496772641365965, 'colsample_bytree': 0.8866798631302921, 'eta': 0.2812866021928349, 'learning_rate': 0.06110258182137581, 'reg_alpha': 2, 'reg_lambda': 0, 'gamma': 3}. Best is trial 1 with value: 0.8825137000000002.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:51:29,432]\u001b[0m Trial 2 finished with value: 0.8497664 and parameters: {'n_estimators': 577, 'max_depth': 1, 'min_child_weight': 7, 'subsample': 0.7983555327300942, 'colsample_bytree': 0.9420110972973017, 'eta': 0.29859639440708285, 'learning_rate': 0.04106272075869888, 'reg_alpha': 5, 'reg_lambda': 0, 'gamma': 5}. Best is trial 1 with value: 0.8825137000000002.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:51:39,755]\u001b[0m Trial 3 finished with value: 0.8674868 and parameters: {'n_estimators': 916, 'max_depth': 1, 'min_child_weight': 10, 'subsample': 0.23284904838709616, 'colsample_bytree': 0.4416634525682326, 'eta': 0.2934689369247007, 'learning_rate': 0.44678639823174976, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 3}. Best is trial 1 with value: 0.8825137000000002.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:51:58,141]\u001b[0m Trial 4 finished with value: 0.8661575000000001 and parameters: {'n_estimators': 392, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.4157365892510977, 'colsample_bytree': 0.5804128067318086, 'eta': 0.07863407842587046, 'learning_rate': 0.381630570791474, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 3}. Best is trial 1 with value: 0.8825137000000002.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:52:43,131]\u001b[0m Trial 5 finished with value: 0.8826818000000001 and parameters: {'n_estimators': 790, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.5859547820439996, 'colsample_bytree': 0.6055798914861953, 'eta': 0.08680410289360914, 'learning_rate': 0.030370645182028887, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 1}. Best is trial 5 with value: 0.8826818000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:52:43,792]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:52:44,817]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:53:10,119]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:53:14,307]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:53:15,521]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:54:29,423]\u001b[0m Trial 11 finished with value: 0.8872123999999999 and parameters: {'n_estimators': 253, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.5783544986858081, 'colsample_bytree': 0.999026024262824, 'eta': 0.22978770745323135, 'learning_rate': 0.040314109553746376, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 0}. Best is trial 11 with value: 0.8872123999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:54:53,182]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:55:58,880]\u001b[0m Trial 13 finished with value: 0.8870773 and parameters: {'n_estimators': 260, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6563828207757852, 'colsample_bytree': 0.742818874634216, 'eta': 0.060150751377814254, 'learning_rate': 0.08845126633414942, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 11 with value: 0.8872123999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:56:51,362]\u001b[0m Trial 14 finished with value: 0.8907621999999998 and parameters: {'n_estimators': 222, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.7279806128413566, 'colsample_bytree': 0.9849904983148858, 'eta': 0.050690736342967405, 'learning_rate': 0.09884103448232359, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 14 with value: 0.8907621999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:56:55,657]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:57:51,277]\u001b[0m Trial 16 finished with value: 0.8861542 and parameters: {'n_estimators': 190, 'max_depth': 5, 'min_child_weight': 2, 'subsample': 0.9007067172069586, 'colsample_bytree': 0.8706510002474206, 'eta': 0.13653336027173077, 'learning_rate': 0.16755544991687654, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 0}. Best is trial 14 with value: 0.8907621999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:57:55,937]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:57:57,326]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:57:58,983]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:58:00,314]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:00,877]\u001b[0m Trial 21 finished with value: 0.8886430000000001 and parameters: {'n_estimators': 264, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6586228439679505, 'colsample_bytree': 0.7118332119602316, 'eta': 0.06297577699943906, 'learning_rate': 0.08188356141686651, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 14 with value: 0.8907621999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:03,660]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:09,931]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:42,529]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 70.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:44,793]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:45,705]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:46,906]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:54,167]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:55,669]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 12:59:56,724]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:00:56,143]\u001b[0m Trial 31 finished with value: 0.8857128000000001 and parameters: {'n_estimators': 267, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6587301105369612, 'colsample_bytree': 0.751654000649961, 'eta': 0.06016457874994586, 'learning_rate': 0.1022922253767653, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 14 with value: 0.8907621999999998.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:01:53,272]\u001b[0m Trial 32 finished with value: 0.8909221 and parameters: {'n_estimators': 233, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6579667273234102, 'colsample_bytree': 0.7601778645609961, 'eta': 0.06589639554045947, 'learning_rate': 0.07601948870841253, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 32 with value: 0.8909221.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:01:58,135]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:01:59,621]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:02:01,499]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:02:03,649]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:02:04,814]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:02:20,856]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:02:21,787]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:02:25,907]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:03:25,691]\u001b[0m Trial 41 finished with value: 0.8872354 and parameters: {'n_estimators': 278, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.6447757642163473, 'colsample_bytree': 0.7281854090591224, 'eta': 0.061543184646849595, 'learning_rate': 0.09933584286314179, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 32 with value: 0.8909221.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:03:27,271]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:20,336]\u001b[0m Trial 43 finished with value: 0.8863554 and parameters: {'n_estimators': 235, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.7505621053339302, 'colsample_bytree': 0.6953918871882417, 'eta': 0.10444728345002484, 'learning_rate': 0.11292829224042124, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 2}. Best is trial 32 with value: 0.8909221.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:21,560]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:25,599]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:27,156]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:28,162]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:29,607]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:04:31,326]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:05:05,852]\u001b[0m A new study created in memory with name: no-name-4ed14401-514e-4fcb-83e0-5a1de0ddbe1d\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:05:39,541]\u001b[0m Trial 0 finished with value: 0.8542566 and parameters: {'n_estimators': 719, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.4950313997888587, 'colsample_bytree': 0.6075693322759934, 'eta': 0.06103449703760937, 'learning_rate': 0.349543795116047, 'reg_alpha': 0, 'reg_lambda': 2, 'gamma': 3}. Best is trial 0 with value: 0.8542566.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:05:57,269]\u001b[0m Trial 1 finished with value: 0.8754939 and parameters: {'n_estimators': 970, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.4865517821361013, 'colsample_bytree': 0.48512491452325346, 'eta': 0.22650479638607668, 'learning_rate': 0.25149334432327886, 'reg_alpha': 1, 'reg_lambda': 5, 'gamma': 5}. Best is trial 1 with value: 0.8754939.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:07:03,628]\u001b[0m Trial 2 finished with value: 0.8757392999999999 and parameters: {'n_estimators': 286, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.658797616717657, 'colsample_bytree': 0.8077702675501788, 'eta': 0.09033643459925435, 'learning_rate': 0.29008118983207404, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 2}. Best is trial 2 with value: 0.8757392999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:09,394]\u001b[0m Trial 3 finished with value: 0.8730534999999999 and parameters: {'n_estimators': 857, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.6171232351192586, 'colsample_bytree': 0.7380963331373149, 'eta': 0.12422913673865653, 'learning_rate': 0.2861967000233574, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 2}. Best is trial 2 with value: 0.8757392999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:26,609]\u001b[0m Trial 4 finished with value: 0.8835127999999999 and parameters: {'n_estimators': 641, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.25268616165595514, 'colsample_bytree': 0.31183043222348394, 'eta': 0.22541915897074705, 'learning_rate': 0.09635483558087714, 'reg_alpha': 1, 'reg_lambda': 4, 'gamma': 4}. Best is trial 4 with value: 0.8835127999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:27,344]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:28,145]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:28,980]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:30,143]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:31,173]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:33,594]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:35,025]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:36,168]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:37,331]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:38,272]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:39,145]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:41,094]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:42,289]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:43,038]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:44,295]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:51,630]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:52,715]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:53,387]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:54,270]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:55,367]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:56,370]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:57,262]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:58,436]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:08:59,489]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:09:04,764]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:09:05,659]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:09:12,953]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:09:18,559]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:09:24,114]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:25,171]\u001b[0m Trial 34 finished with value: 0.8688572999999999 and parameters: {'n_estimators': 965, 'max_depth': 11, 'min_child_weight': 9, 'subsample': 0.5676553392567399, 'colsample_bytree': 0.8819262617808491, 'eta': 0.1548282836209993, 'learning_rate': 0.27558603682277416, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 2}. Best is trial 4 with value: 0.8835127999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:26,308]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:27,694]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:28,765]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:29,710]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:30,849]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:31,800]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:10:39,066]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:43,663]\u001b[0m Trial 42 finished with value: 0.8704769000000001 and parameters: {'n_estimators': 954, 'max_depth': 12, 'min_child_weight': 9, 'subsample': 0.6484205965320395, 'colsample_bytree': 0.8155792776602322, 'eta': 0.1739013412755407, 'learning_rate': 0.28131864628629377, 'reg_alpha': 1, 'reg_lambda': 1, 'gamma': 2}. Best is trial 4 with value: 0.8835127999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:45,579]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:46,717]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:51,127]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:52,808]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:54,098]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:55,697]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:11:57,847]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:12:11,900]\u001b[0m A new study created in memory with name: no-name-7939b1d4-08fb-421e-a620-b3ee3b87cd24\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:12:39,321]\u001b[0m Trial 0 finished with value: 0.8863494 and parameters: {'n_estimators': 18, 'max_depth': 4, 'min_child_weight': 6, 'subsample': 0.4516213242065244, 'colsample_bytree': 0.8418751355319627, 'eta': 0.19322421622335129, 'learning_rate': 0.040421891523994814, 'reg_alpha': 2, 'reg_lambda': 3, 'gamma': 4}. Best is trial 0 with value: 0.8863494.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:13:23,736]\u001b[0m Trial 1 finished with value: 0.8748150000000001 and parameters: {'n_estimators': 434, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.5093687652899384, 'colsample_bytree': 0.6182704245683498, 'eta': 0.2049840661341099, 'learning_rate': 0.0066249782060554, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 5}. Best is trial 0 with value: 0.8863494.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:13:31,561]\u001b[0m Trial 2 finished with value: 0.8865974999999999 and parameters: {'n_estimators': 683, 'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.5129627988617849, 'colsample_bytree': 0.24820629924341803, 'eta': 0.23777272517025977, 'learning_rate': 0.09235510087642648, 'reg_alpha': 0, 'reg_lambda': 2, 'gamma': 4}. Best is trial 2 with value: 0.8865974999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:13:39,433]\u001b[0m Trial 3 finished with value: 0.8847259 and parameters: {'n_estimators': 576, 'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.41762369693292467, 'colsample_bytree': 0.24617594997694667, 'eta': 0.15565855257166594, 'learning_rate': 0.25047757106650714, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 4}. Best is trial 2 with value: 0.8865974999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:14:08,149]\u001b[0m Trial 4 finished with value: 0.886505 and parameters: {'n_estimators': 620, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.3466901859776984, 'colsample_bytree': 0.9182882726510517, 'eta': 0.09371476762746277, 'learning_rate': 0.11500146432952281, 'reg_alpha': 2, 'reg_lambda': 0, 'gamma': 1}. Best is trial 2 with value: 0.8865974999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:14:54,190]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 62.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:15:49,973]\u001b[0m Trial 6 finished with value: 0.8820361999999999 and parameters: {'n_estimators': 949, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.7793361789470161, 'colsample_bytree': 0.845944513973311, 'eta': 0.27300095436187893, 'learning_rate': 0.26879728238167283, 'reg_alpha': 5, 'reg_lambda': 1, 'gamma': 3}. Best is trial 2 with value: 0.8865974999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:15:51,082]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:15:52,242]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:15:54,162]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:15:55,111]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:15:56,164]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:16:31,590]\u001b[0m Trial 12 finished with value: 0.8913815999999999 and parameters: {'n_estimators': 766, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.5949229739753358, 'colsample_bytree': 0.6836928423692, 'eta': 0.15208116677028677, 'learning_rate': 0.10825181238601878, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 2}. Best is trial 12 with value: 0.8913815999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:16:32,745]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:16:34,177]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:16:35,677]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:16:36,704]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:17:25,258]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 46.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:17:26,105]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:17:27,087]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:17:28,108]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:17:57,380]\u001b[0m Trial 21 finished with value: 0.886402 and parameters: {'n_estimators': 636, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.33973605144220603, 'colsample_bytree': 0.8129150040344163, 'eta': 0.09592112949185605, 'learning_rate': 0.13020740441717363, 'reg_alpha': 2, 'reg_lambda': 0, 'gamma': 1}. Best is trial 12 with value: 0.8913815999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:30,559]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:31,872]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:41,479]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 23.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:42,746]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:43,840]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:45,084]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:46,257]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:47,498]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:48,342]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:51,609]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:53,238]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:18:54,183]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:19:50,420]\u001b[0m Trial 34 finished with value: 0.8907092000000001 and parameters: {'n_estimators': 452, 'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.5031833972959531, 'colsample_bytree': 0.9425340714063735, 'eta': 0.09950120753190812, 'learning_rate': 0.08095033344289569, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 2}. Best is trial 12 with value: 0.8913815999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:20:07,415]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:20:24,465]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 29.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:21:29,936]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 94.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:21:30,735]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:21:36,049]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:21:51,379]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 24.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:01,260]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 33.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:01,982]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:03,975]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:05,243]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:06,343]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:07,271]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:08,589]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:09,658]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:22:10,633]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:23:06,663]\u001b[0m A new study created in memory with name: no-name-1f38baef-452e-4e7e-8134-b3ef36747410\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:23:44,511]\u001b[0m Trial 0 finished with value: 0.8564342 and parameters: {'n_estimators': 217, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.23312107548917843, 'colsample_bytree': 0.9390325117163418, 'eta': 0.25402067279581253, 'learning_rate': 0.005415020015040688, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 1}. Best is trial 0 with value: 0.8564342.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:24:12,079]\u001b[0m Trial 1 finished with value: 0.861887 and parameters: {'n_estimators': 495, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.885719762577913, 'colsample_bytree': 0.35302218717498113, 'eta': 0.06283426421774231, 'learning_rate': 0.007620568771938729, 'reg_alpha': 0, 'reg_lambda': 4, 'gamma': 5}. Best is trial 1 with value: 0.861887.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:24:26,782]\u001b[0m Trial 2 finished with value: 0.8310606 and parameters: {'n_estimators': 755, 'max_depth': 1, 'min_child_weight': 10, 'subsample': 0.667742903689458, 'colsample_bytree': 0.775321238453319, 'eta': 0.21057622338857324, 'learning_rate': 0.025893927738913837, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 5}. Best is trial 1 with value: 0.861887.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:24:48,255]\u001b[0m Trial 3 finished with value: 0.890229 and parameters: {'n_estimators': 464, 'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.7452384649627997, 'colsample_bytree': 0.9710778828506992, 'eta': 0.18927898368629392, 'learning_rate': 0.2985995192242841, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 2}. Best is trial 3 with value: 0.890229.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:25:56,291]\u001b[0m Trial 4 finished with value: 0.8725391 and parameters: {'n_estimators': 964, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.8454102319783972, 'colsample_bytree': 0.7899722828609632, 'eta': 0.25465816986102946, 'learning_rate': 0.01880461402478978, 'reg_alpha': 4, 'reg_lambda': 4, 'gamma': 4}. Best is trial 3 with value: 0.890229.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:26:26,349]\u001b[0m Trial 5 finished with value: 0.8664376 and parameters: {'n_estimators': 476, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.20199950114344586, 'colsample_bytree': 0.8995433447522996, 'eta': 0.1880787840564071, 'learning_rate': 0.18214698105063512, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 1}. Best is trial 3 with value: 0.890229.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:27:23,036]\u001b[0m Trial 6 finished with value: 0.8926439 and parameters: {'n_estimators': 311, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.7890646677807032, 'colsample_bytree': 0.6851542865236919, 'eta': 0.22392986165970724, 'learning_rate': 0.09110957607986392, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:27:24,180]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:27:25,275]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:27:26,478]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:28:05,694]\u001b[0m Trial 10 finished with value: 0.8893317999999999 and parameters: {'n_estimators': 4, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.4942576094978827, 'colsample_bytree': 0.6041427994073172, 'eta': 0.12765511224388892, 'learning_rate': 0.05644282509074214, 'reg_alpha': 5, 'reg_lambda': 0, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:28:46,008]\u001b[0m Trial 11 finished with value: 0.8652925999999999 and parameters: {'n_estimators': 246, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.7305802553245759, 'colsample_bytree': 0.6747723062458321, 'eta': 0.15292737543933863, 'learning_rate': 0.48792787666085735, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 2}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:28:46,998]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:29:37,438]\u001b[0m Trial 13 finished with value: 0.8829366000000001 and parameters: {'n_estimators': 689, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.5737913291028661, 'colsample_bytree': 0.9772689908207229, 'eta': 0.12068522197524284, 'learning_rate': 0.17635384366513032, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 1}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:29:38,205]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:30:35,983]\u001b[0m Trial 15 finished with value: 0.8753838999999999 and parameters: {'n_estimators': 282, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8038120774944887, 'colsample_bytree': 0.6957290283706017, 'eta': 0.20575933339782543, 'learning_rate': 0.3024295191238881, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:30:37,074]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:30:54,463]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 48.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:30:57,568]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:30:58,872]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:00,009]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:01,379]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:02,523]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:03,498]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:11,108]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:12,146]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:14,667]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:15,897]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:31,919]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:34,883]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:31:37,950]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:32:28,850]\u001b[0m Trial 31 finished with value: 0.8849199999999999 and parameters: {'n_estimators': 715, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.5817282351680582, 'colsample_bytree': 0.9724874207211962, 'eta': 0.12254559510870837, 'learning_rate': 0.16276686556645426, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 1}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:32:30,038]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:32:31,573]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:33:31,748]\u001b[0m Trial 34 finished with value: 0.8879134000000001 and parameters: {'n_estimators': 499, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.86078073725738, 'colsample_bytree': 0.9470593366241346, 'eta': 0.20127133511969814, 'learning_rate': 0.1364698330741122, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:34:50,875]\u001b[0m Trial 35 finished with value: 0.8903548000000001 and parameters: {'n_estimators': 539, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.8890075805535007, 'colsample_bytree': 0.7871985026234856, 'eta': 0.21084974929067013, 'learning_rate': 0.13620024282599197, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:36:00,763]\u001b[0m Trial 36 finished with value: 0.8863494 and parameters: {'n_estimators': 642, 'max_depth': 9, 'min_child_weight': 10, 'subsample': 0.9100489837661302, 'colsample_bytree': 0.7865957084503613, 'eta': 0.2406250739511566, 'learning_rate': 0.2285336335494198, 'reg_alpha': 0, 'reg_lambda': 4, 'gamma': 5}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:36:07,499]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:36:48,856]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 59.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:36:54,363]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:36:56,059]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:37:56,932]\u001b[0m Trial 41 finished with value: 0.8926089999999999 and parameters: {'n_estimators': 491, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.8353924876114658, 'colsample_bytree': 0.8928315263446853, 'eta': 0.20044612542545898, 'learning_rate': 0.12884663953105832, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:38:05,975]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:39:09,437]\u001b[0m Trial 43 finished with value: 0.8885143 and parameters: {'n_estimators': 396, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.7622329007110834, 'colsample_bytree': 0.8247652614164476, 'eta': 0.1781710901783704, 'learning_rate': 0.13879263310136328, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 0}. Best is trial 6 with value: 0.8926439.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:39:52,375]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 43.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:39:55,851]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:39:57,744]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:40:19,777]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 34.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:40:22,265]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:40:23,043]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:41:02,484]\u001b[0m A new study created in memory with name: no-name-cc9f4565-f28b-4045-b837-2060c6fe92e7\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:41:17,723]\u001b[0m Trial 0 finished with value: 0.8181428000000001 and parameters: {'n_estimators': 216, 'max_depth': 1, 'min_child_weight': 10, 'subsample': 0.8790945152577887, 'colsample_bytree': 0.748149769499342, 'eta': 0.18523113205143754, 'learning_rate': 0.022021381331630507, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 3}. Best is trial 0 with value: 0.8181428000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:41:43,444]\u001b[0m Trial 1 finished with value: 0.8697012000000001 and parameters: {'n_estimators': 122, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.6026252878750961, 'colsample_bytree': 0.9320142252825494, 'eta': 0.0672085905149226, 'learning_rate': 0.023047815093202324, 'reg_alpha': 0, 'reg_lambda': 2, 'gamma': 1}. Best is trial 1 with value: 0.8697012000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:07,477]\u001b[0m Trial 2 finished with value: 0.8901156 and parameters: {'n_estimators': 545, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.8616878371330481, 'colsample_bytree': 0.7205577863543187, 'eta': 0.15250059122435644, 'learning_rate': 0.09426370849169019, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 1}. Best is trial 2 with value: 0.8901156.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:23,456]\u001b[0m Trial 3 finished with value: 0.8532395000000002 and parameters: {'n_estimators': 900, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.6826788956992422, 'colsample_bytree': 0.2573166887668619, 'eta': 0.11437420395758001, 'learning_rate': 0.014035960441561742, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 2}. Best is trial 2 with value: 0.8901156.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:46,754]\u001b[0m Trial 4 finished with value: 0.8598088 and parameters: {'n_estimators': 831, 'max_depth': 11, 'min_child_weight': 7, 'subsample': 0.2992229937398599, 'colsample_bytree': 0.29643330370258003, 'eta': 0.246202123953576, 'learning_rate': 0.19105501182043225, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 2}. Best is trial 2 with value: 0.8901156.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:47,721]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:48,916]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:50,523]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:51,730]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:43:54,428]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:46:53,965]\u001b[0m Trial 10 finished with value: 0.8962512 and parameters: {'n_estimators': 439, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.9974205161378475, 'colsample_bytree': 0.9785478164239358, 'eta': 0.17223589328201627, 'learning_rate': 0.10838451518133976, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 5}. Best is trial 10 with value: 0.8962512.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:50:30,895]\u001b[0m Trial 11 finished with value: 0.8968621000000001 and parameters: {'n_estimators': 470, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.9882737836280486, 'colsample_bytree': 0.9648403047292708, 'eta': 0.17409458774485065, 'learning_rate': 0.11837378426811765, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 5}. Best is trial 11 with value: 0.8968621000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:50:33,188]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:53:11,694]\u001b[0m Trial 13 finished with value: 0.8971419 and parameters: {'n_estimators': 373, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.9856309798408553, 'colsample_bytree': 0.8825482064180691, 'eta': 0.19865138137549582, 'learning_rate': 0.07693688706279364, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 5}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:53:13,739]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:55:00,119]\u001b[0m Trial 15 finished with value: 0.8877637 and parameters: {'n_estimators': 325, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7528058869381756, 'colsample_bytree': 0.5306128754662054, 'eta': 0.29672261989793264, 'learning_rate': 0.23093988654406453, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 4}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:55:03,303]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:55:05,041]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:55:06,590]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:55:11,515]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:57:54,366]\u001b[0m Trial 20 finished with value: 0.8950546000000001 and parameters: {'n_estimators': 404, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.74050194489833, 'colsample_bytree': 0.8884840165722669, 'eta': 0.2429188199316926, 'learning_rate': 0.10188631516214326, 'reg_alpha': 2, 'reg_lambda': 3, 'gamma': 5}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:57:56,645]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:58:00,401]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:58:02,529]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:58:04,796]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:58:08,013]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 13:58:10,053]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:00:30,932]\u001b[0m Trial 27 finished with value: 0.894838 and parameters: {'n_estimators': 538, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9231672556664006, 'colsample_bytree': 0.8950818672312897, 'eta': 0.27051499535743895, 'learning_rate': 0.13498840685774788, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 5}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:00:32,693]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:00:33,786]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:01:46,829]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:04:16,864]\u001b[0m Trial 31 finished with value: 0.8941939 and parameters: {'n_estimators': 426, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8877930121575671, 'colsample_bytree': 0.8578102418408661, 'eta': 0.24436635633316434, 'learning_rate': 0.10050473344290108, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 5}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:04:19,121]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:04:57,125]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 25.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:04:59,197]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:06:26,714]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:06:29,053]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:06:32,417]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:06:34,846]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:06:36,469]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:06:38,015]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:08:53,060]\u001b[0m Trial 41 finished with value: 0.8962663999999998 and parameters: {'n_estimators': 543, 'max_depth': 10, 'min_child_weight': 6, 'subsample': 0.9246107903493687, 'colsample_bytree': 0.8948551543045613, 'eta': 0.2758662609847723, 'learning_rate': 0.12334496132982921, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 5}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:08:54,209]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:08:55,979]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:08:59,326]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:11:11,357]\u001b[0m Trial 45 finished with value: 0.8955746000000001 and parameters: {'n_estimators': 425, 'max_depth': 11, 'min_child_weight': 8, 'subsample': 0.9996127676828602, 'colsample_bytree': 0.8668421192189167, 'eta': 0.28013479086648724, 'learning_rate': 0.21301600575871676, 'reg_alpha': 4, 'reg_lambda': 5, 'gamma': 5}. Best is trial 13 with value: 0.8971419.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:11:13,250]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:11:15,370]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:11:17,319]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:11:19,051]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the XGBoost model, uses optuna for HP tuning, get accuracy, indices and probabilities for each fold\n",
    "xgb_ts_k_fold_results, xgb_ts_test_sets_index, xgb_ts_predicted_probas, xgb_ts_observed, xgb_ts_shap, _, xgb_ts_hps = ml_help.k_fold_accuracies(X, y, strat, False, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228e38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in dictionary\n",
    "xgb_ts_results = {'X':X,\n",
    "                'probas':xgb_ts_predicted_probas, \n",
    "              'observed':xgb_ts_observed, \n",
    "              'shap':xgb_ts_shap\n",
    "              }\n",
    "\n",
    "with open(dict_directory+\"xgb_ts\", \"wb\") as fp:   \n",
    "    #Pickling \n",
    "    pickle.dump(xgb_ts_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c42660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the mean accuracy to a table for easy perusal\n",
    "mean_results = ml_help.add_mean_to_df(mean_results, xgb_ts_k_fold_results, 'xgb', 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2ff94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a probability column to the whole dataset to ensure \n",
    "df_with_probas = ml_help.add_proba_col(df_with_probas, xgb_ts_test_sets_index, xgb_ts_predicted_probas , 'probas_xgb_ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b373ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "xgb_ts_k_fold_results.to_csv(k_fold_results_directory+'xgb_ts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837a53fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hyperparameters\n",
    "pd.DataFrame(xgb_ts_hps).to_csv('../../results/hyperparameters/xgb_ts.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed931c5d-5670-414c-9bdf-803574a098fe",
   "metadata": {},
   "source": [
    "## 3.2. Two features\n",
    "Two features shown in the feature selection process to be the most important, start glucose and duration of exercise bout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc413e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the two features from feature selection\n",
    "X_two = X[['start_glc','duration']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09642357",
   "metadata": {},
   "source": [
    "### 3.2.1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475b054-8ca6-4beb-9d54-540d56bde7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the LR model, uses hyperopt for HP tuning, get accuracy, indices and probabilities for each fold\n",
    "lr_two_k_fold_results, lr_two_test_sets_index, lr_two_predicted_probas, lr_two_observed, lr_two_shap_values, lr_two_coeffs, lr_two_hps = ml_help.k_fold_accuracies(X_two, y, strat, True, 'two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in dictionary\n",
    "lr_two_results = {'X':X_two,\n",
    "              'probas':lr_two_predicted_probas, \n",
    "              'observed':lr_two_observed, \n",
    "              'shap':lr_two_shap_values, \n",
    "              'coeffs':lr_two_coeffs}\n",
    "\n",
    "with open(dict_directory+\"lr_two\", \"wb\") as fp:   \n",
    "    #Pickling \n",
    "    pickle.dump(lr_two_results, fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d00e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the mean accuracy to a table for easy perusal\n",
    "mean_results = ml_help.add_mean_to_df(mean_results, lr_two_k_fold_results, 'lr', 'two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fe908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a probability column to the whole dataset to ensure \n",
    "df_with_probas = ml_help.add_proba_col(df_with_probas, lr_two_test_sets_index, lr_two_predicted_probas, 'probas_lr_two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f490ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "lr_two_k_fold_results.to_csv(k_fold_results_directory+'lr_two.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hyperparameters\n",
    "pd.DataFrame(lr_two_hps).to_csv('../../results/hyperparameters/lr_two.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f429303a",
   "metadata": {},
   "source": [
    "### 3.2.2. XGB Two feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69ac2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-10-30 14:13:19,690]\u001b[0m A new study created in memory with name: no-name-a5540dc0-2192-4ddf-a9ab-124bfd1b0930\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:24,618]\u001b[0m Trial 0 finished with value: 0.8405521 and parameters: {'n_estimators': 207, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6788315281094192, 'colsample_bytree': 0.2565112644833512, 'eta': 0.13154834097839968, 'learning_rate': 0.3787177706320947, 'reg_alpha': 2, 'reg_lambda': 4, 'gamma': 1}. Best is trial 0 with value: 0.8405521.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:28,523]\u001b[0m Trial 1 finished with value: 0.8425812 and parameters: {'n_estimators': 736, 'max_depth': 11, 'min_child_weight': 2, 'subsample': 0.9097718966999266, 'colsample_bytree': 0.22107554840927018, 'eta': 0.2853302193665385, 'learning_rate': 0.018449659902107726, 'reg_alpha': 4, 'reg_lambda': 2, 'gamma': 2}. Best is trial 1 with value: 0.8425812.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:34,891]\u001b[0m Trial 2 finished with value: 0.8461703999999999 and parameters: {'n_estimators': 21, 'max_depth': 11, 'min_child_weight': 7, 'subsample': 0.6870391686589958, 'colsample_bytree': 0.28255290268118316, 'eta': 0.13311797543720338, 'learning_rate': 0.005569354779682042, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 3}. Best is trial 2 with value: 0.8461703999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:40,979]\u001b[0m Trial 3 finished with value: 0.8453065000000001 and parameters: {'n_estimators': 289, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.8815241589864569, 'colsample_bytree': 0.41187477586359533, 'eta': 0.18958019672807463, 'learning_rate': 0.32503560175270163, 'reg_alpha': 2, 'reg_lambda': 0, 'gamma': 2}. Best is trial 2 with value: 0.8461703999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:44,828]\u001b[0m Trial 4 finished with value: 0.845858 and parameters: {'n_estimators': 244, 'max_depth': 7, 'min_child_weight': 9, 'subsample': 0.3078085094267576, 'colsample_bytree': 0.2855189581620852, 'eta': 0.25631796898709386, 'learning_rate': 0.3443508812822865, 'reg_alpha': 5, 'reg_lambda': 0, 'gamma': 3}. Best is trial 2 with value: 0.8461703999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:44,883]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:44,951]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,013]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,066]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,130]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,209]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,291]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,376]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,482]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,575]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,676]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,778]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,880]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:45,963]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:46,101]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:46,182]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:47,315]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:47,435]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:47,549]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:47,842]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:47,948]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,131]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,243]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,330]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,409]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,495]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,607]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,704]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,816]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:48,915]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,018]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,150]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,412]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,504]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,598]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,681]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,764]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,848]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:49,935]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:50,030]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:53,525]\u001b[0m Trial 45 finished with value: 0.8487912999999999 and parameters: {'n_estimators': 496, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.7858759872459898, 'colsample_bytree': 0.2247292025308191, 'eta': 0.05430627098057804, 'learning_rate': 0.20682744930665714, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 4}. Best is trial 45 with value: 0.8487912999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:53,656]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:53,755]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:53,941]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:54,032]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:13:56,483]\u001b[0m A new study created in memory with name: no-name-e5323d7f-4bee-4837-a450-54de9322c985\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:02,130]\u001b[0m Trial 0 finished with value: 0.8379247 and parameters: {'n_estimators': 124, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.6697704413340104, 'colsample_bytree': 0.36455129601009145, 'eta': 0.14300534835847234, 'learning_rate': 0.1016846837306364, 'reg_alpha': 0, 'reg_lambda': 2, 'gamma': 0}. Best is trial 0 with value: 0.8379247.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:05,231]\u001b[0m Trial 1 finished with value: 0.8375577 and parameters: {'n_estimators': 772, 'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.4162971558289423, 'colsample_bytree': 0.5637921327504678, 'eta': 0.2562194973619177, 'learning_rate': 0.01642095623717398, 'reg_alpha': 4, 'reg_lambda': 5, 'gamma': 5}. Best is trial 0 with value: 0.8379247.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:08,118]\u001b[0m Trial 2 finished with value: 0.8470791999999999 and parameters: {'n_estimators': 803, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.9517851942737439, 'colsample_bytree': 0.9991705186404569, 'eta': 0.12423709095356965, 'learning_rate': 0.29909844140231384, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 4}. Best is trial 2 with value: 0.8470791999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:13,034]\u001b[0m Trial 3 finished with value: 0.8448656 and parameters: {'n_estimators': 403, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.8952308884754681, 'colsample_bytree': 0.2884874718022743, 'eta': 0.21994749843376266, 'learning_rate': 0.10679457539929794, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 0}. Best is trial 2 with value: 0.8470791999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,552]\u001b[0m Trial 4 finished with value: 0.8469369999999999 and parameters: {'n_estimators': 208, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.8343107867803092, 'colsample_bytree': 0.6186638579577004, 'eta': 0.20023493003454612, 'learning_rate': 0.10544716735672825, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 1}. Best is trial 2 with value: 0.8470791999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,633]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,680]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,734]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,793]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,854]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:16,977]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:17,060]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:17,208]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:18,663]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:18,778]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:18,873]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:18,955]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,035]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,119]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,204]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,294]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,494]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,596]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,680]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,763]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,845]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:19,939]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:20,057]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:20,162]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:20,245]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:20,328]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:20,502]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:20,582]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:22,309]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:22,450]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:22,600]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:22,722]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:22,996]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,096]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,201]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,280]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,364]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,443]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,526]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,659]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,796]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,875]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:23,979]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:24,162]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:24,680]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:28,001]\u001b[0m A new study created in memory with name: no-name-02c8558f-c3d8-41c0-b017-d75c5ea053f9\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:33,091]\u001b[0m Trial 0 finished with value: 0.8490174000000001 and parameters: {'n_estimators': 289, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.2957368003032998, 'colsample_bytree': 0.25862688321792593, 'eta': 0.237166293807769, 'learning_rate': 0.24360827542984742, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 5}. Best is trial 0 with value: 0.8490174000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:36,383]\u001b[0m Trial 1 finished with value: 0.8521251 and parameters: {'n_estimators': 824, 'max_depth': 3, 'min_child_weight': 7, 'subsample': 0.8142552749576137, 'colsample_bytree': 0.5987441648757421, 'eta': 0.10861235059884618, 'learning_rate': 0.11144364758358812, 'reg_alpha': 2, 'reg_lambda': 4, 'gamma': 4}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:40,179]\u001b[0m Trial 2 finished with value: 0.8420314 and parameters: {'n_estimators': 365, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.4614023746660181, 'colsample_bytree': 0.724129651464489, 'eta': 0.13432081053430606, 'learning_rate': 0.014718737516476406, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 1}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:44,036]\u001b[0m Trial 3 finished with value: 0.8473438999999999 and parameters: {'n_estimators': 742, 'max_depth': 11, 'min_child_weight': 4, 'subsample': 0.21274611135597477, 'colsample_bytree': 0.6942833698401951, 'eta': 0.28323628917432836, 'learning_rate': 0.038458599043963024, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 4}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:48,401]\u001b[0m Trial 4 finished with value: 0.8387789000000001 and parameters: {'n_estimators': 338, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.9645567415567069, 'colsample_bytree': 0.48110414671241897, 'eta': 0.2923077166228417, 'learning_rate': 0.2611256024394756, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 0}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:49,336]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 19.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:49,393]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:49,469]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:49,517]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:49,571]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:49,673]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:50,030]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:55,263]\u001b[0m Trial 12 finished with value: 0.8509729 and parameters: {'n_estimators': 413, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.8424891211939726, 'colsample_bytree': 0.3836430523594988, 'eta': 0.21153662742795049, 'learning_rate': 0.116595365413085, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 4}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:55,744]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:14:59,982]\u001b[0m Trial 14 finished with value: 0.8512278999999999 and parameters: {'n_estimators': 494, 'max_depth': 7, 'min_child_weight': 7, 'subsample': 0.854195605337106, 'colsample_bytree': 0.351035887903974, 'eta': 0.22431772145902018, 'learning_rate': 0.10812039403003476, 'reg_alpha': 1, 'reg_lambda': 4, 'gamma': 3}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:00,061]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:00,144]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:01,517]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 28.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:01,607]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:01,708]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:01,795]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:01,909]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:01,997]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:02,085]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:07,697]\u001b[0m Trial 24 finished with value: 0.8477276 and parameters: {'n_estimators': 185, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.6820703785053694, 'colsample_bytree': 0.498097231140583, 'eta': 0.26125052689160616, 'learning_rate': 0.3368683824038764, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 5}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:12,061]\u001b[0m Trial 25 finished with value: 0.8516868000000001 and parameters: {'n_estimators': 657, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.9223815545767695, 'colsample_bytree': 0.4166150867821436, 'eta': 0.18260547907557212, 'learning_rate': 0.1489181158277836, 'reg_alpha': 1, 'reg_lambda': 4, 'gamma': 4}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:12,156]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:12,453]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:12,539]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,071]\u001b[0m Trial 29 finished with value: 0.8514797 and parameters: {'n_estimators': 863, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.9150114044583935, 'colsample_bytree': 0.6534631298393125, 'eta': 0.24969126393832386, 'learning_rate': 0.17349210124150558, 'reg_alpha': 1, 'reg_lambda': 5, 'gamma': 5}. Best is trial 1 with value: 0.8521251.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,184]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,271]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,346]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,478]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,606]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:17,718]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:19,746]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:19,842]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:19,952]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,084]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,168]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,258]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,358]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,468]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,579]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,665]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:20,838]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:21,028]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:21,137]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:21,279]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:25,526]\u001b[0m A new study created in memory with name: no-name-2700bb79-2fbb-4344-b26d-562f07a30ac5\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:29,001]\u001b[0m Trial 0 finished with value: 0.8340454000000002 and parameters: {'n_estimators': 638, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.61449275844906, 'colsample_bytree': 0.6844676069529056, 'eta': 0.07731835664052218, 'learning_rate': 0.005397444722734275, 'reg_alpha': 4, 'reg_lambda': 3, 'gamma': 2}. Best is trial 0 with value: 0.8340454000000002.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:33,626]\u001b[0m Trial 1 finished with value: 0.8467548 and parameters: {'n_estimators': 880, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8589358927176804, 'colsample_bytree': 0.9466469963965045, 'eta': 0.12323302969731566, 'learning_rate': 0.3958070424552105, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 5}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:39,018]\u001b[0m Trial 2 finished with value: 0.8465756000000001 and parameters: {'n_estimators': 847, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.6190595651118465, 'colsample_bytree': 0.20858465413544308, 'eta': 0.09063270950394957, 'learning_rate': 0.426773570052194, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 5}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:42,921]\u001b[0m Trial 3 finished with value: 0.8354493 and parameters: {'n_estimators': 701, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.605476721742648, 'colsample_bytree': 0.39442802722537484, 'eta': 0.24461406886179599, 'learning_rate': 0.007240866920564087, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 5}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:47,002]\u001b[0m Trial 4 finished with value: 0.8461647999999998 and parameters: {'n_estimators': 562, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.33822382890514363, 'colsample_bytree': 0.2719381409623791, 'eta': 0.13967740391403433, 'learning_rate': 0.27323175846455644, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 3}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:47,052]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:47,101]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:47,150]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:47,199]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:50,616]\u001b[0m Trial 9 finished with value: 0.8457942 and parameters: {'n_estimators': 16, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.38432750720054865, 'colsample_bytree': 0.41877634486489523, 'eta': 0.2501886203769472, 'learning_rate': 0.2388522669589566, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 5}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:50,708]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:50,799]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:50,949]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:51,420]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:51,525]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:51,807]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:51,898]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,046]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,197]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,314]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,418]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,522]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,618]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,709]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,793]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:52,893]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,005]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,152]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,241]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,349]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,434]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,553]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:53,637]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:57,590]\u001b[0m Trial 33 finished with value: 0.8451971 and parameters: {'n_estimators': 2, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.38874485140315723, 'colsample_bytree': 0.2633838622781858, 'eta': 0.2525499983968789, 'learning_rate': 0.3607529626363988, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 5}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:57,690]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:57,770]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:57,975]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:58,068]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:58,212]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:58,309]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:15:58,397]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:02,388]\u001b[0m Trial 41 finished with value: 0.8427260000000001 and parameters: {'n_estimators': 1, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.39969549812561417, 'colsample_bytree': 0.2511702892993179, 'eta': 0.26514079464561513, 'learning_rate': 0.37407476480736723, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 5}. Best is trial 1 with value: 0.8467548.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:03,137]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:03,456]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:03,555]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:03,682]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:03,941]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:04,163]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:04,252]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:04,338]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:10,872]\u001b[0m A new study created in memory with name: no-name-44683c4b-9c20-49be-b50e-db496b2b72d8\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:14,315]\u001b[0m Trial 0 finished with value: 0.8403953 and parameters: {'n_estimators': 404, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.40332071834842487, 'colsample_bytree': 0.26285980781571183, 'eta': 0.16910518137081854, 'learning_rate': 0.0062436519596463826, 'reg_alpha': 2, 'reg_lambda': 2, 'gamma': 5}. Best is trial 0 with value: 0.8403953.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:16,932]\u001b[0m Trial 1 finished with value: 0.8516119 and parameters: {'n_estimators': 767, 'max_depth': 1, 'min_child_weight': 9, 'subsample': 0.5409307738933429, 'colsample_bytree': 0.4446008015453071, 'eta': 0.17793094168890955, 'learning_rate': 0.26328558407052294, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 2}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:21,648]\u001b[0m Trial 2 finished with value: 0.8506449 and parameters: {'n_estimators': 943, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.8148538292161271, 'colsample_bytree': 0.21008047289919596, 'eta': 0.17944379019029488, 'learning_rate': 0.16826392197642126, 'reg_alpha': 5, 'reg_lambda': 4, 'gamma': 5}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:24,319]\u001b[0m Trial 3 finished with value: 0.8486349000000001 and parameters: {'n_estimators': 777, 'max_depth': 1, 'min_child_weight': 2, 'subsample': 0.78456818414865, 'colsample_bytree': 0.22057040259181093, 'eta': 0.28582932872465583, 'learning_rate': 0.06115608095339696, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 2}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:28,921]\u001b[0m Trial 4 finished with value: 0.8475655999999999 and parameters: {'n_estimators': 995, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9919909052967639, 'colsample_bytree': 0.7853784560752444, 'eta': 0.16202062682504453, 'learning_rate': 0.10968204910160467, 'reg_alpha': 0, 'reg_lambda': 5, 'gamma': 1}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:28,987]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:29,415]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:29,502]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:29,684]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:29,740]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:29,830]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:29,919]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:30,008]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:34,526]\u001b[0m Trial 13 finished with value: 0.8509492999999999 and parameters: {'n_estimators': 900, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.7988207013527956, 'colsample_bytree': 0.6194584651722981, 'eta': 0.215911364624036, 'learning_rate': 0.4009346487925742, 'reg_alpha': 4, 'reg_lambda': 4, 'gamma': 4}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:34,616]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:34,721]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:34,819]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:34,922]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:38,671]\u001b[0m Trial 18 finished with value: 0.8446776999999999 and parameters: {'n_estimators': 585, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.847745077131429, 'colsample_bytree': 0.510971643417041, 'eta': 0.24732626582870165, 'learning_rate': 0.24382864580005217, 'reg_alpha': 2, 'reg_lambda': 3, 'gamma': 0}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:38,744]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:38,818]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:39,114]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:43,650]\u001b[0m Trial 22 finished with value: 0.8507 and parameters: {'n_estimators': 888, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.8703960342391852, 'colsample_bytree': 0.4105276866034082, 'eta': 0.1484057234899647, 'learning_rate': 0.30278478421145005, 'reg_alpha': 5, 'reg_lambda': 4, 'gamma': 5}. Best is trial 1 with value: 0.8516119.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:48,007]\u001b[0m Trial 23 finished with value: 0.8516999000000001 and parameters: {'n_estimators': 788, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.9062248768631718, 'colsample_bytree': 0.42988945056106476, 'eta': 0.1447748425700666, 'learning_rate': 0.3012066545161291, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 4}. Best is trial 23 with value: 0.8516999000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:48,106]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:52,074]\u001b[0m Trial 25 finished with value: 0.8511728 and parameters: {'n_estimators': 820, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.8988627891208365, 'colsample_bytree': 0.536136132509787, 'eta': 0.1983505168369189, 'learning_rate': 0.3381699821511082, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 2}. Best is trial 23 with value: 0.8516999000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:56,130]\u001b[0m Trial 26 finished with value: 0.8508508000000001 and parameters: {'n_estimators': 455, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.9026343266754455, 'colsample_bytree': 0.5607177557482749, 'eta': 0.14986322678279823, 'learning_rate': 0.2949087780873798, 'reg_alpha': 5, 'reg_lambda': 2, 'gamma': 2}. Best is trial 23 with value: 0.8516999000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:56,229]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:56,362]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:56,481]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:16:56,586]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:02,273]\u001b[0m Trial 31 finished with value: 0.8508924999999999 and parameters: {'n_estimators': 822, 'max_depth': 6, 'min_child_weight': 4, 'subsample': 0.8545612289880884, 'colsample_bytree': 0.5480709887591692, 'eta': 0.22861222427914904, 'learning_rate': 0.37028376239194494, 'reg_alpha': 4, 'reg_lambda': 3, 'gamma': 3}. Best is trial 23 with value: 0.8516999000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:02,389]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:02,612]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:02,732]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:02,874]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:02,981]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:03,112]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:03,271]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:03,374]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:03,499]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:03,662]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:09,020]\u001b[0m Trial 42 finished with value: 0.8513867000000002 and parameters: {'n_estimators': 931, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.9313636164161789, 'colsample_bytree': 0.5329702515303396, 'eta': 0.20273209790476135, 'learning_rate': 0.3935955505989238, 'reg_alpha': 5, 'reg_lambda': 2, 'gamma': 3}. Best is trial 23 with value: 0.8516999000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:09,230]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:12,153]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 58.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:12,395]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:12,484]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:12,617]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:12,756]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:12,889]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:20,257]\u001b[0m A new study created in memory with name: no-name-ac7eaca3-d395-4202-b086-07a55965fa73\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:25,702]\u001b[0m Trial 0 finished with value: 0.8337825000000001 and parameters: {'n_estimators': 835, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.9804530515341539, 'colsample_bytree': 0.8362549996260957, 'eta': 0.1450788873741483, 'learning_rate': 0.20308603436626826, 'reg_alpha': 0, 'reg_lambda': 5, 'gamma': 0}. Best is trial 0 with value: 0.8337825000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:28,834]\u001b[0m Trial 1 finished with value: 0.8398109 and parameters: {'n_estimators': 716, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.2697600433860299, 'colsample_bytree': 0.8648334558581585, 'eta': 0.2007070839625565, 'learning_rate': 0.017167408457364718, 'reg_alpha': 5, 'reg_lambda': 4, 'gamma': 2}. Best is trial 1 with value: 0.8398109.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:32,288]\u001b[0m Trial 2 finished with value: 0.8381926 and parameters: {'n_estimators': 887, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.2477615199495208, 'colsample_bytree': 0.2556855499575783, 'eta': 0.250105826691562, 'learning_rate': 0.0064823417951848546, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 4}. Best is trial 1 with value: 0.8398109.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:35,690]\u001b[0m Trial 3 finished with value: 0.8345295 and parameters: {'n_estimators': 924, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.9045423802036374, 'colsample_bytree': 0.8587364631727747, 'eta': 0.21020887233845453, 'learning_rate': 0.005121838633604024, 'reg_alpha': 4, 'reg_lambda': 5, 'gamma': 3}. Best is trial 1 with value: 0.8398109.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:38,893]\u001b[0m Trial 4 finished with value: 0.8391057999999999 and parameters: {'n_estimators': 410, 'max_depth': 2, 'min_child_weight': 4, 'subsample': 0.571731592887093, 'colsample_bytree': 0.3542989150158573, 'eta': 0.19432111477537672, 'learning_rate': 0.010950363030481821, 'reg_alpha': 5, 'reg_lambda': 2, 'gamma': 2}. Best is trial 1 with value: 0.8398109.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:42,205]\u001b[0m Trial 5 finished with value: 0.8434780999999999 and parameters: {'n_estimators': 308, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.9181084947970115, 'colsample_bytree': 0.9038275979484651, 'eta': 0.08471735700233286, 'learning_rate': 0.012367347289607318, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 4}. Best is trial 5 with value: 0.8434780999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:46,785]\u001b[0m Trial 6 finished with value: 0.8502448000000001 and parameters: {'n_estimators': 717, 'max_depth': 12, 'min_child_weight': 9, 'subsample': 0.47746631547217594, 'colsample_bytree': 0.4185020155626298, 'eta': 0.2255502494315917, 'learning_rate': 0.15556204094049905, 'reg_alpha': 4, 'reg_lambda': 1, 'gamma': 5}. Best is trial 6 with value: 0.8502448000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:46,887]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:46,967]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:50,220]\u001b[0m Trial 9 finished with value: 0.8502008 and parameters: {'n_estimators': 556, 'max_depth': 2, 'min_child_weight': 10, 'subsample': 0.48507589027801423, 'colsample_bytree': 0.8644895492323408, 'eta': 0.24923804835772273, 'learning_rate': 0.19973479151813378, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 0}. Best is trial 6 with value: 0.8502448000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:55,104]\u001b[0m Trial 10 finished with value: 0.849621 and parameters: {'n_estimators': 571, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.7001202602232759, 'colsample_bytree': 0.5763222940526981, 'eta': 0.2689757623046614, 'learning_rate': 0.05762087321234783, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 5}. Best is trial 6 with value: 0.8502448000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:55,214]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:55,327]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,008]\u001b[0m Trial 13 finished with value: 0.8474976999999999 and parameters: {'n_estimators': 463, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7496669458215459, 'colsample_bytree': 0.9910616137021818, 'eta': 0.29953641233162326, 'learning_rate': 0.4404148213471805, 'reg_alpha': 4, 'reg_lambda': 4, 'gamma': 1}. Best is trial 6 with value: 0.8502448000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,105]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,189]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,275]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,360]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,458]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,551]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,639]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:17:59,942]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:05,254]\u001b[0m Trial 22 finished with value: 0.8503961999999999 and parameters: {'n_estimators': 544, 'max_depth': 11, 'min_child_weight': 10, 'subsample': 0.6573751205920284, 'colsample_bytree': 0.4904092111020299, 'eta': 0.27090472547166744, 'learning_rate': 0.20148322784086697, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 4}. Best is trial 22 with value: 0.8503961999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:05,348]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:05,518]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:05,596]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:10,259]\u001b[0m Trial 26 finished with value: 0.8500414 and parameters: {'n_estimators': 649, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.6653036879592549, 'colsample_bytree': 0.6439596047046315, 'eta': 0.2867447256663661, 'learning_rate': 0.2777223484645819, 'reg_alpha': 5, 'reg_lambda': 1, 'gamma': 3}. Best is trial 22 with value: 0.8503961999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:10,366]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:14,703]\u001b[0m Trial 28 finished with value: 0.8499677 and parameters: {'n_estimators': 755, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.8071117711763522, 'colsample_bytree': 0.40771721182214354, 'eta': 0.1854314711145889, 'learning_rate': 0.22366797244153375, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 5}. Best is trial 22 with value: 0.8503961999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:14,789]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:14,873]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,026]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,171]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,283]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,379]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,477]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,557]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:15,661]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:20,721]\u001b[0m Trial 38 finished with value: 0.8487221 and parameters: {'n_estimators': 340, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.8143581371498635, 'colsample_bytree': 0.605824902354635, 'eta': 0.21263519956448962, 'learning_rate': 0.4944137195099539, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 3}. Best is trial 22 with value: 0.8503961999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:20,810]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:20,903]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:21,050]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:25,856]\u001b[0m Trial 42 finished with value: 0.8498989 and parameters: {'n_estimators': 542, 'max_depth': 7, 'min_child_weight': 10, 'subsample': 0.8938805350143336, 'colsample_bytree': 0.41584403340135273, 'eta': 0.16637075555308764, 'learning_rate': 0.22996609374419388, 'reg_alpha': 3, 'reg_lambda': 5, 'gamma': 5}. Best is trial 22 with value: 0.8503961999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,270]\u001b[0m Trial 43 finished with value: 0.8502605000000001 and parameters: {'n_estimators': 692, 'max_depth': 5, 'min_child_weight': 9, 'subsample': 0.7558365514119825, 'colsample_bytree': 0.3310282790767426, 'eta': 0.190202098891624, 'learning_rate': 0.35935299137175936, 'reg_alpha': 3, 'reg_lambda': 4, 'gamma': 5}. Best is trial 22 with value: 0.8503961999999999.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,351]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,442]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,533]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,675]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,803]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:30,959]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:36,202]\u001b[0m A new study created in memory with name: no-name-95c7327d-e8ce-47a2-b0b8-7fe7047e2e13\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:41,576]\u001b[0m Trial 0 finished with value: 0.8478254 and parameters: {'n_estimators': 161, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.4192305005034087, 'colsample_bytree': 0.4998751416543189, 'eta': 0.1430882187879255, 'learning_rate': 0.037186953036257485, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 4}. Best is trial 0 with value: 0.8478254.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:46,544]\u001b[0m Trial 1 finished with value: 0.8484826 and parameters: {'n_estimators': 999, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.6932716581226432, 'colsample_bytree': 0.2258588622799449, 'eta': 0.28508705308788146, 'learning_rate': 0.11402521557380749, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 1}. Best is trial 1 with value: 0.8484826.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:51,286]\u001b[0m Trial 2 finished with value: 0.8478559000000001 and parameters: {'n_estimators': 798, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.4366043888841598, 'colsample_bytree': 0.9997812952592267, 'eta': 0.1394661544717009, 'learning_rate': 0.21536322374733557, 'reg_alpha': 4, 'reg_lambda': 2, 'gamma': 3}. Best is trial 1 with value: 0.8484826.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:54,630]\u001b[0m Trial 3 finished with value: 0.838438 and parameters: {'n_estimators': 846, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8025845103944844, 'colsample_bytree': 0.561933464084206, 'eta': 0.211574768887978, 'learning_rate': 0.005369734008728114, 'reg_alpha': 1, 'reg_lambda': 5, 'gamma': 1}. Best is trial 1 with value: 0.8484826.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:57,502]\u001b[0m Trial 4 finished with value: 0.8447145 and parameters: {'n_estimators': 768, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.8898546013984445, 'colsample_bytree': 0.46831561114721443, 'eta': 0.24051782104683395, 'learning_rate': 0.01551850993315662, 'reg_alpha': 1, 'reg_lambda': 3, 'gamma': 5}. Best is trial 1 with value: 0.8484826.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:18:57,551]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,193]\u001b[0m Trial 6 finished with value: 0.8500650000000001 and parameters: {'n_estimators': 591, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.95505888898803, 'colsample_bytree': 0.8400283766021195, 'eta': 0.15477830024946537, 'learning_rate': 0.4980131351224997, 'reg_alpha': 0, 'reg_lambda': 5, 'gamma': 5}. Best is trial 6 with value: 0.8500650000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,247]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,304]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,409]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,499]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,597]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,820]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:02,966]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,054]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,150]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,245]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,335]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,542]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,633]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,748]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,835]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:03,951]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:04,079]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:04,182]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:04,270]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:04,418]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:04,499]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:04,589]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:05,141]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:05,302]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:05,656]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 7.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:05,754]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:05,874]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:05,996]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:06,138]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:06,270]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:10,167]\u001b[0m Trial 37 finished with value: 0.8471982 and parameters: {'n_estimators': 867, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.5484556676739173, 'colsample_bytree': 0.5053281309648565, 'eta': 0.08128121614526615, 'learning_rate': 0.37360740054239344, 'reg_alpha': 1, 'reg_lambda': 5, 'gamma': 4}. Best is trial 6 with value: 0.8500650000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:10,267]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:10,371]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:12,755]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 36.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:16,207]\u001b[0m Trial 41 finished with value: 0.8477911 and parameters: {'n_estimators': 853, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.5719472993481606, 'colsample_bytree': 0.4994103206449645, 'eta': 0.07491688699980739, 'learning_rate': 0.39362223356154435, 'reg_alpha': 1, 'reg_lambda': 5, 'gamma': 4}. Best is trial 6 with value: 0.8500650000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:16,335]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:20,633]\u001b[0m Trial 43 finished with value: 0.8476754 and parameters: {'n_estimators': 899, 'max_depth': 6, 'min_child_weight': 10, 'subsample': 0.641650822001283, 'colsample_bytree': 0.5468100232090857, 'eta': 0.07289771358166952, 'learning_rate': 0.27678322977860553, 'reg_alpha': 0, 'reg_lambda': 5, 'gamma': 4}. Best is trial 6 with value: 0.8500650000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:20,717]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:20,799]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:20,881]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:21,683]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:21,767]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:21,844]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:27,503]\u001b[0m A new study created in memory with name: no-name-73c14af0-76bf-468c-96bf-72aaaf953c1b\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:31,448]\u001b[0m Trial 0 finished with value: 0.8499106000000001 and parameters: {'n_estimators': 131, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.44720899950646936, 'colsample_bytree': 0.6409713990966024, 'eta': 0.25311931009583266, 'learning_rate': 0.08621026166523554, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 4}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:34,459]\u001b[0m Trial 1 finished with value: 0.8378736 and parameters: {'n_estimators': 625, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.404356028652217, 'colsample_bytree': 0.30159073178247064, 'eta': 0.2755468152679085, 'learning_rate': 0.009155010986136075, 'reg_alpha': 5, 'reg_lambda': 4, 'gamma': 3}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:36,943]\u001b[0m Trial 2 finished with value: 0.8498362 and parameters: {'n_estimators': 124, 'max_depth': 1, 'min_child_weight': 5, 'subsample': 0.5404438031593863, 'colsample_bytree': 0.48971340222649423, 'eta': 0.2819741161437099, 'learning_rate': 0.19804428622135245, 'reg_alpha': 2, 'reg_lambda': 5, 'gamma': 4}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:40,763]\u001b[0m Trial 3 finished with value: 0.8465759 and parameters: {'n_estimators': 440, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.41545751306638956, 'colsample_bytree': 0.5369209156119468, 'eta': 0.1750686189477339, 'learning_rate': 0.14031642882425371, 'reg_alpha': 2, 'reg_lambda': 3, 'gamma': 1}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:46,034]\u001b[0m Trial 4 finished with value: 0.8373172999999999 and parameters: {'n_estimators': 401, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.34867776733031985, 'colsample_bytree': 0.4033123620979761, 'eta': 0.12800213562363455, 'learning_rate': 0.14209011594813428, 'reg_alpha': 0, 'reg_lambda': 3, 'gamma': 1}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:46,101]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:46,902]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:47,157]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:47,269]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:47,326]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:47,585]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:47,713]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:47,817]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:52,094]\u001b[0m Trial 13 finished with value: 0.8485007 and parameters: {'n_estimators': 259, 'max_depth': 5, 'min_child_weight': 5, 'subsample': 0.5545049079001818, 'colsample_bytree': 0.21756576873738653, 'eta': 0.2981293624034867, 'learning_rate': 0.41467195361747344, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 4}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:52,270]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:57,328]\u001b[0m Trial 15 finished with value: 0.8492659 and parameters: {'n_estimators': 295, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.552816169632838, 'colsample_bytree': 0.47406973466262176, 'eta': 0.24981312764190022, 'learning_rate': 0.2276321404053836, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 5}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:57,605]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:57,702]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:57,821]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:57,943]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:19:58,056]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:03,203]\u001b[0m Trial 21 finished with value: 0.8485543999999999 and parameters: {'n_estimators': 307, 'max_depth': 12, 'min_child_weight': 6, 'subsample': 0.5311424886953487, 'colsample_bytree': 0.4811415869189065, 'eta': 0.25142830462229804, 'learning_rate': 0.2734598378454829, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 5}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:03,536]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:03,798]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:04,058]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:04,388]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:04,473]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:04,580]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:07,571]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 79.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:07,659]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:07,774]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:13,310]\u001b[0m Trial 31 finished with value: 0.8488361 and parameters: {'n_estimators': 284, 'max_depth': 12, 'min_child_weight': 5, 'subsample': 0.5313129762968005, 'colsample_bytree': 0.45202169828924665, 'eta': 0.2457693800115593, 'learning_rate': 0.2722030384726928, 'reg_alpha': 3, 'reg_lambda': 1, 'gamma': 5}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:13,394]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:13,504]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:13,592]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:13,914]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:14,786]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:14,907]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:15,009]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:19,550]\u001b[0m Trial 39 finished with value: 0.8489568999999999 and parameters: {'n_estimators': 915, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9892434731601788, 'colsample_bytree': 0.6931144969805358, 'eta': 0.22488026111142156, 'learning_rate': 0.3187379690260106, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 5}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:21,824]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 35.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:22,232]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:22,801]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 9.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:22,922]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:26,551]\u001b[0m Trial 44 finished with value: 0.8484581 and parameters: {'n_estimators': 699, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.7678862546885125, 'colsample_bytree': 0.6093799624103715, 'eta': 0.25681230764737795, 'learning_rate': 0.49478805357372835, 'reg_alpha': 3, 'reg_lambda': 2, 'gamma': 4}. Best is trial 0 with value: 0.8499106000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:26,690]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:26,933]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:27,032]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:27,243]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:27,490]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:28,472]\u001b[0m A new study created in memory with name: no-name-2bf1c844-bd9a-41ef-af1c-1c3a6cfc67c1\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:32,366]\u001b[0m Trial 0 finished with value: 0.8462892 and parameters: {'n_estimators': 978, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.3641566286889806, 'colsample_bytree': 0.920048363689508, 'eta': 0.10419852471628109, 'learning_rate': 0.0774119245054549, 'reg_alpha': 1, 'reg_lambda': 2, 'gamma': 0}. Best is trial 0 with value: 0.8462892.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:37,201]\u001b[0m Trial 1 finished with value: 0.8452844 and parameters: {'n_estimators': 109, 'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.5013521098270606, 'colsample_bytree': 0.7707212606072333, 'eta': 0.10083862998997518, 'learning_rate': 0.02368085375390713, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 3}. Best is trial 0 with value: 0.8462892.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:40,848]\u001b[0m Trial 2 finished with value: 0.8379787999999999 and parameters: {'n_estimators': 466, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.4030492906127167, 'colsample_bytree': 0.7193069539219663, 'eta': 0.10274019011729917, 'learning_rate': 0.014982596042138719, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 4}. Best is trial 0 with value: 0.8462892.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:45,701]\u001b[0m Trial 3 finished with value: 0.8477105000000001 and parameters: {'n_estimators': 694, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6473768290342764, 'colsample_bytree': 0.8223057417511581, 'eta': 0.14637170890673834, 'learning_rate': 0.2613378879655315, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 2}. Best is trial 3 with value: 0.8477105000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:48,353]\u001b[0m Trial 4 finished with value: 0.8436739 and parameters: {'n_estimators': 574, 'max_depth': 2, 'min_child_weight': 2, 'subsample': 0.8133208311396325, 'colsample_bytree': 0.9347796711990417, 'eta': 0.29290851573516424, 'learning_rate': 0.02838903304842452, 'reg_alpha': 5, 'reg_lambda': 3, 'gamma': 2}. Best is trial 3 with value: 0.8477105000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:48,401]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:48,447]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:48,507]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:48,584]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:48,677]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,268]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,354]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,452]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,668]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,752]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,829]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:53,923]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:54,024]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:54,105]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:54,189]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:54,320]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:54,663]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:54,751]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:55,063]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:55,156]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:55,239]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:55,612]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 8.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:55,708]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:55,856]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,038]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,152]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,239]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,358]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,484]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,597]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,686]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,773]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,860]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:56,969]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:20:57,093]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:02,045]\u001b[0m Trial 40 finished with value: 0.8444267999999999 and parameters: {'n_estimators': 619, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5958778522937563, 'colsample_bytree': 0.5699687355132514, 'eta': 0.061471193384638564, 'learning_rate': 0.06077022975824815, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 3 with value: 0.8477105000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:07,007]\u001b[0m Trial 41 finished with value: 0.8434367 and parameters: {'n_estimators': 621, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.6039531412738584, 'colsample_bytree': 0.5298984554649576, 'eta': 0.06810225682455502, 'learning_rate': 0.07431745748456384, 'reg_alpha': 1, 'reg_lambda': 0, 'gamma': 1}. Best is trial 3 with value: 0.8477105000000001.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:08,417]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 31.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:08,590]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:08,700]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:08,815]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:08,916]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:09,016]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:10,839]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 38.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:10,933]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:16,408]\u001b[0m A new study created in memory with name: no-name-efb9d6d7-7876-4d88-a203-753bf95d1ff9\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:21,484]\u001b[0m Trial 0 finished with value: 0.8537559 and parameters: {'n_estimators': 222, 'max_depth': 12, 'min_child_weight': 7, 'subsample': 0.4590720731637914, 'colsample_bytree': 0.536084199092586, 'eta': 0.05981002376116158, 'learning_rate': 0.21026388354665645, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 3}. Best is trial 0 with value: 0.8537559.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:24,811]\u001b[0m Trial 1 finished with value: 0.8491652000000001 and parameters: {'n_estimators': 106, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.6899157093801345, 'colsample_bytree': 0.7599836613771487, 'eta': 0.13448344820941305, 'learning_rate': 0.02941313637880279, 'reg_alpha': 2, 'reg_lambda': 0, 'gamma': 4}. Best is trial 0 with value: 0.8537559.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:29,712]\u001b[0m Trial 2 finished with value: 0.8440193 and parameters: {'n_estimators': 416, 'max_depth': 8, 'min_child_weight': 9, 'subsample': 0.7524424712230902, 'colsample_bytree': 0.33136860396110795, 'eta': 0.09899848423212367, 'learning_rate': 0.2476062854661079, 'reg_alpha': 2, 'reg_lambda': 4, 'gamma': 0}. Best is trial 0 with value: 0.8537559.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:33,786]\u001b[0m Trial 3 finished with value: 0.8493641999999999 and parameters: {'n_estimators': 992, 'max_depth': 11, 'min_child_weight': 3, 'subsample': 0.7926313694408873, 'colsample_bytree': 0.4819131791501617, 'eta': 0.15985741980703128, 'learning_rate': 0.023276995326359462, 'reg_alpha': 3, 'reg_lambda': 0, 'gamma': 1}. Best is trial 0 with value: 0.8537559.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:37,487]\u001b[0m Trial 4 finished with value: 0.8498853000000001 and parameters: {'n_estimators': 77, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.2945132824369532, 'colsample_bytree': 0.9388237551129961, 'eta': 0.2275869490546213, 'learning_rate': 0.04610283596009013, 'reg_alpha': 3, 'reg_lambda': 3, 'gamma': 3}. Best is trial 0 with value: 0.8537559.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:37,735]\u001b[0m Trial 5 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:37,819]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:37,944]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:41,591]\u001b[0m Trial 8 finished with value: 0.8525056 and parameters: {'n_estimators': 431, 'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.5047123771728421, 'colsample_bytree': 0.4195154253353326, 'eta': 0.14088575699613315, 'learning_rate': 0.046090357136175854, 'reg_alpha': 0, 'reg_lambda': 1, 'gamma': 3}. Best is trial 0 with value: 0.8537559.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:41,645]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:41,730]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:41,817]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:41,902]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:41,984]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,083]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,183]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,272]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,366]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,454]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,587]\u001b[0m Trial 19 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,671]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,768]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,869]\u001b[0m Trial 22 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:42,983]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,073]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,161]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,253]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,338]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,426]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,537]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,626]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,718]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:43,992]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,092]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,189]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,345]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,432]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,542]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,626]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,744]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:44,827]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,286]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,508]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,594]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,679]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,776]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,873]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:45,970]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:46,104]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2023-10-30 14:21:46,237]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 0.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the XGBoost model, uses optuna for HP tuning, get accuracy, indices and probabilities for each fold\n",
    "xgb_two_k_fold_results, xgb_two_test_sets_index, xgb_two_predicted_probas, xgb_two_observed, xgb_two_shap, _, xgb_two_hps = ml_help.k_fold_accuracies(X_two, y, strat, False, 'two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175cc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in dictionary\n",
    "xgb_two_results = {'X':X_two, \n",
    "                'probas':xgb_two_predicted_probas, \n",
    "                'observed':xgb_two_observed, \n",
    "                'shap':xgb_two_shap\n",
    "                }\n",
    "\n",
    "with open(dict_directory+\"xgb_results_two\", \"wb\") as fp:   \n",
    "    #Pickling \n",
    "    pickle.dump(xgb_two_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f91cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the mean accuracy to a table for easy perusal\n",
    "mean_results = ml_help.add_mean_to_df(mean_results, xgb_two_k_fold_results, 'xgb', 'two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mae</th>\n",
       "      <th>logloss</th>\n",
       "      <th>brier</th>\n",
       "      <th>threshold</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>predicted_positive_rate</th>\n",
       "      <th>observed_positive_rate</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>specificity</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.889252</td>\n",
       "      <td>0.107016</td>\n",
       "      <td>0.210281</td>\n",
       "      <td>0.059696</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.782025</td>\n",
       "      <td>0.286857</td>\n",
       "      <td>0.830823</td>\n",
       "      <td>0.422824</td>\n",
       "      <td>0.280530</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.830823</td>\n",
       "      <td>0.223097</td>\n",
       "      <td>0.776903</td>\n",
       "      <td>0.803863</td>\n",
       "      <td>xgb</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.848677</td>\n",
       "      <td>0.126934</td>\n",
       "      <td>0.227582</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.750451</td>\n",
       "      <td>0.251883</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.377385</td>\n",
       "      <td>0.302469</td>\n",
       "      <td>0.0944</td>\n",
       "      <td>0.780359</td>\n",
       "      <td>0.252574</td>\n",
       "      <td>0.747426</td>\n",
       "      <td>0.763893</td>\n",
       "      <td>xgb</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roc_auc       mae   logloss     brier  threshold  accuracy  precision  \\\n",
       "mean  0.889252  0.107016  0.210281  0.059696      0.060  0.782025   0.286857   \n",
       "mean  0.848677  0.126934  0.227582  0.064119      0.082  0.750451   0.251883   \n",
       "\n",
       "        recall        f1  predicted_positive_rate  observed_positive_rate  \\\n",
       "mean  0.830823  0.422824                 0.280530                  0.0944   \n",
       "mean  0.780359  0.377385                 0.302469                  0.0944   \n",
       "\n",
       "           tpr       fpr  specificity  balanced_accuracy model features  \n",
       "mean  0.830823  0.223097     0.776903           0.803863   xgb      all  \n",
       "mean  0.780359  0.252574     0.747426           0.763893   xgb      two  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df78c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a probability column to the whole dataset to ensure \n",
    "df_with_probas = ml_help.add_proba_col(df_with_probas, xgb_two_test_sets_index, xgb_two_predicted_probas , 'probas_xgb_two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb3a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save k-fold results\n",
    "xgb_two_k_fold_results.to_csv(k_fold_results_directory+'xgb_two.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd38e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save hyperparameters\n",
    "pd.DataFrame(xgb_two_hps).to_csv('../../results/hyperparameters/xgb_two.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9163b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe with all predicted probas\n",
    "df_with_probas.to_csv('../../results/probability_results/xgb_two.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_cgm_env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "11957cbc5b69a14c5eed2137b8c383ab027096f0c9ca0d6fd5201f30e0447e4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
